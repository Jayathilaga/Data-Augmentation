{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayathilaga/Data-Augmentation/blob/main/data_aug_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5n1sEeyKL1u"
      },
      "source": [
        "# Installing the [Kaggle API](https://github.com/Kaggle/kaggle-api) in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-G42lKMmGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3918e740-4333-434a-8335-b43033a0adbc"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install nlpaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.6/dist-packages (0.0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBCMEuahMyH6"
      },
      "source": [
        "# Authenticating with Kaggle using kaggle.json\n",
        "\n",
        "Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "\n",
        "Then run the cell below to upload kaggle.json to your Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkaEYzZkMl5T",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "c164744e-ead5-4cdf-99e3-8641b7dbc255"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0aae1b43-99ed-4e6f-abc7-c1c917a97eb6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0aae1b43-99ed-4e6f-abc7-c1c917a97eb6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 64 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdIts_4M5Me"
      },
      "source": [
        "# Downloading required data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyNO0frwKZkg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d1e05dbb-d07e-4781-dd22-e9a02015d137"
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started\n",
        "!kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "glove-global-vectors-for-word-representation.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX9_PCMuTBlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d078060c-eb99-41db-eda8-367a55a0ddfa"
      },
      "source": [
        "! unzip /content/glove-global-vectors-for-word-representation.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove-global-vectors-for-word-representation.zip\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pp2KF30OVU2"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHUSSHH1KL1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcd0b073-3dfd-4935-f05c-6cf2aa7b572c"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "plt.style.use('ggplot')\n",
        "stop=set(stopwords.words('english'))\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "import string\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEud_6KHKL2E"
      },
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as naf\n",
        "\n",
        "from nlpaug.util import Action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfvi9HIWKL2K"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZxVL2NVKL2W"
      },
      "source": [
        "## Loading the data and getting basic idea "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxx4dutMKL2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e39698da-02a0-4d29-b6be-40cf9e704d0e"
      },
      "source": [
        "tweet= pd.read_csv('/content/train.csv')\n",
        "test=pd.read_csv('/content/test.csv')\n",
        "tweet.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEAGD_0uKL2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b84ad422-6725-4e9a-c8e5-e28a97f965e1"
      },
      "source": [
        "print('There are {} rows and {} columns in train'.format(tweet.shape[0],tweet.shape[1]))\n",
        "print('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 7613 rows and 5 columns in train\n",
            "There are 3263 rows and 4 columns in train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yls-W2oJKL2h"
      },
      "source": [
        "tweet=tweet.drop(['keyword','location'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_NmXrD1KL2m"
      },
      "source": [
        "## Class distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFYvDIyfKL2n"
      },
      "source": [
        "Before we begin with anything else,let's check the class distribution.There are only two classes 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJuD3jmEKL2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "98c5b04a-234e-40c1-93cf-fb02932c0738"
      },
      "source": [
        "x=tweet.target.value_counts()\n",
        "sns.barplot(x.index,x)\n",
        "plt.gca().set_ylabel('samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'samples')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOdBX3AJKL2t"
      },
      "source": [
        "ohh,as expected ! There is a class distribution.There are more tweets with class 0 ( No disaster) than class 1 ( disaster tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pnGpPgKL2u"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAXWJIqjKL2v"
      },
      "source": [
        "# model_type: word2vec, glove or fasttext\n",
        "aug_w2v = naw.WordEmbsAug(\n",
        "#     model_type='word2vec', model_path='../input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin',\n",
        "    model_type='glove', model_path='/content/glove.6B.100d.txt',\n",
        "    action=\"substitute\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AiLFrswKL20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8689ec99-ebe5-4440-cb69-8a16e18a3038"
      },
      "source": [
        "text = tweet.iloc[0]['text']\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_1U_PuvKL26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ea9203cc-ed41-48a1-c764-3a58c1fb3996"
      },
      "source": [
        "aug_w2v.aug_p=0.2\n",
        "print(\"Augmented Text:\")\n",
        "for ii in range(5):\n",
        "    augmented_text = aug_w2v.augment(text)\n",
        "    print(augmented_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmented Text:\n",
            "Our Deeds already the Reason what this # earthquake May ALLAH Forgive us all\n",
            "Our Deeds having up Reason of this # earthquake May ALLAH Forgive us all\n",
            "Our Deeds are the Reason of present # quakes May ALLAH Forgive us all\n",
            "Our Deeds many the Reason of this # temblor May ALLAH Forgive us all\n",
            "Our Deeds either been Reason of this # earthquake May ALLAH Forgive us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1JOQpbEKL29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2111a27-4f77-4826-c584-922c52c4b3d3"
      },
      "source": [
        "train,valid=train_test_split(tweet,test_size=0.15)\n",
        "print('Shape of train',train.shape)\n",
        "print(\"Shape of Validation \",valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train (6471, 3)\n",
            "Shape of Validation  (1142, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNv3AhTLKL3C"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def augment_text(df,samples=300,pr=0.2):\n",
        "    aug_w2v.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    ##dropping samples from validation\n",
        "    df_n=df[df.target==1].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['text']\n",
        "            augmented_text = aug_w2v.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'text':new_text,'target':1})\n",
        "    df=shuffle(df.append(new).reset_index(drop=True))\n",
        "    return df\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMYRx5rdKL3K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e883c44-14f5-4a97-9b30-bbb2a6deaedb"
      },
      "source": [
        "train = augment_text(train,samples=400)   ## change samples to 0 for no augmentation\n",
        "tweet = train.append(valid).reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [01:12<00:00,  5.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itPb5__NKL3O"
      },
      "source": [
        "df=pd.concat([tweet,test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2t3hzMtKL3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae0a243-c010-4d74-a439-f7280f7282fc"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11276, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPN4iEyxKL4L"
      },
      "source": [
        "## GloVe for Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vh4FKTZKL4M"
      },
      "source": [
        "Here we will use GloVe pretrained corpus model to represent our words.It is available in 3 varieties :50D ,100D and 200 Dimentional.We will try 100 D here.\n",
        "This pipeline is described in [this](https://neptune.ai/blog/document-classification-small-datasets) article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgo6HEgfKL4N"
      },
      "source": [
        "\n",
        "def create_corpus(df):\n",
        "    corpus=[]\n",
        "    for tweet in tqdm(df['text']):\n",
        "        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n",
        "        corpus.append(words)\n",
        "    return corpus\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xby3aXQ-KL4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f703972-c8f7-4500-ce76-bb6c0026252f"
      },
      "source": [
        "corpus=create_corpus(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11276/11276 [00:02<00:00, 4450.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3HmcsHCKL4f"
      },
      "source": [
        "embedding_dict={}\n",
        "with open('/content/glove.6B.100d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values=line.split()\n",
        "        word=values[0]\n",
        "        vectors=np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word]=vectors\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdMQiskdKL4h"
      },
      "source": [
        "MAX_LEN=50\n",
        "tokenizer_obj=Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(corpus)\n",
        "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
        "\n",
        "tweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AwnhzsaKL4k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85d8aac0-93a0-46bd-c7f4-8361c04fc40d"
      },
      "source": [
        "word_index=tokenizer_obj.word_index\n",
        "print('Number of unique words:',len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 19034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kw8h7pqKL4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99ed14ff-c440-461a-b551-2963b18f9cb0"
      },
      "source": [
        "num_words=len(word_index)+1\n",
        "embedding_matrix=np.zeros((num_words,100))\n",
        "\n",
        "for word,i in tqdm(word_index.items()):\n",
        "    if i > num_words:\n",
        "        continue\n",
        "    \n",
        "    emb_vec=embedding_dict.get(word)\n",
        "    if emb_vec is not None:\n",
        "        embedding_matrix[i]=emb_vec\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19034/19034 [00:00<00:00, 492588.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuJrV3iwKL4p"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8JW2B4mKL4p"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "embedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n",
        "                   input_length=MAX_LEN,trainable=False)\n",
        "\n",
        "model.add(embedding)\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "optimzer=Adam(learning_rate=1e-5)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7gOFunSKL4r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b87cfefa-378c-4a4a-b860-686510d2d155"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 100)           1903500   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,984,001\n",
            "Trainable params: 80,501\n",
            "Non-trainable params: 1,903,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaQHdfPwKL4v"
      },
      "source": [
        "train_df=tweet_pad[:tweet.shape[0]]\n",
        "test_df=tweet_pad[tweet.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x18oDpcxPAnw"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBS70maMKL4x"
      },
      "source": [
        "X_train,y_train = train_df[:train.shape[0]],tweet['target'][:train.shape[0]]\n",
        "\n",
        "X_test,y_test= train_df[train.shape[0]:],tweet['target'][train.shape[0]:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkI23SqJKL4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "b07e1e54-31c6-4a1a-a505-cbce5525420a"
      },
      "source": [
        "history=model.fit(X_train,y_train,batch_size=4,epochs=10,validation_data=(X_test,y_test),verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6871 samples, validate on 1142 samples\n",
            "Epoch 1/10\n",
            " - 47s - loss: 0.6926 - accuracy: 0.5344 - val_loss: 0.6902 - val_accuracy: 0.5849\n",
            "Epoch 2/10\n",
            " - 45s - loss: 0.6330 - accuracy: 0.6589 - val_loss: 0.5211 - val_accuracy: 0.7680\n",
            "Epoch 3/10\n",
            " - 46s - loss: 0.5710 - accuracy: 0.7289 - val_loss: 0.5090 - val_accuracy: 0.7758\n",
            "Epoch 4/10\n",
            " - 46s - loss: 0.5551 - accuracy: 0.7379 - val_loss: 0.5036 - val_accuracy: 0.7732\n",
            "Epoch 5/10\n",
            " - 45s - loss: 0.5554 - accuracy: 0.7404 - val_loss: 0.4998 - val_accuracy: 0.7767\n",
            "Epoch 6/10\n",
            " - 46s - loss: 0.5470 - accuracy: 0.7452 - val_loss: 0.4986 - val_accuracy: 0.7793\n",
            "Epoch 7/10\n",
            " - 47s - loss: 0.5488 - accuracy: 0.7457 - val_loss: 0.4925 - val_accuracy: 0.7820\n",
            "Epoch 8/10\n",
            " - 46s - loss: 0.5334 - accuracy: 0.7568 - val_loss: 0.4892 - val_accuracy: 0.7855\n",
            "Epoch 9/10\n",
            " - 45s - loss: 0.5344 - accuracy: 0.7559 - val_loss: 0.4948 - val_accuracy: 0.7837\n",
            "Epoch 10/10\n",
            " - 46s - loss: 0.5328 - accuracy: 0.7519 - val_loss: 0.4888 - val_accuracy: 0.7881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwJpG5CvKL43"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8hPfElKL43"
      },
      "source": [
        "y_pre=model.predict(X_test)\n",
        "y_pre=np.round(y_pre).astype(int).reshape(1142)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIU0qYcKL45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fc8f08-13dc-4b4d-a7b0-9293596efc34"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_pre,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7824407958672192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKsm6Q3MKL47"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}